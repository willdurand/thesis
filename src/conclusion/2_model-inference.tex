\section{New challenges in model inference}
\label{sec:conclusion:modelinf}

Model inference is a research field that has received a lot of
attention over the past three decades, and it is still gaining
ground with the emergence of new kinds of applications. Many
recent works consider model inference to later perform analyses
of the models or automatic testing in order to check different
aspects of the software system such as robustness, security, and
even regression testing, as presented in this thesis.
Nonetheless, model inference still has a few drawbacks, which
require further investigation, and we believe that the next three
major directions could be very beneficial.

\subsection{Building exact, or rather, more precise models}
\label{sec:conclusion:modelinf:exact}

When the inferred models are used for analysis purpose
(verification or testing), they must be as precise as possible.
From the literature, we observed that the main feature leading to
over-approximation is the state merging process. A trivial
solution would be to use minimization techniques instead,
\emph{e.g.}, a bisimulation minimization as described in Chapter
\ref{sec:modelinf:webapps} of this thesis.  As a reminder, the
bisimulation relation associated with a minimization technique
merges the state sets that are bisimilar equivalent. This
relation is stronger than a classical trace equivalence relation,
but it may be considered too strong since the bisimulation
minimization usually does not merge enough states, and thus may
still produce large models. If another more suitable relation can
be used, and if verification or testing techniques can work well
with larger yet more precise models, which results can we expect?
In this thesis, we provided a preliminary answer to this question
(which is context-specific), but there is still a lot of work
that could be done.

Another solution to limit non-approximation is to define and
estimate \emph{quality metrics}
\cite{tonella2012finding,Lo20122063} to guide the model
construction. In \cite{tonella2012finding}, three metrics,
related to over- and under-approximation rates and model size,
are measured to balance over-approximation and
under-approximation of the inferred models with two search-based
algorithms: (i) a multi-objective genetic algorithm, and (ii) the
non-dominated sorting genetic algorithm \textit{NSGA-II}
\cite{deb2002fast}. But this process is time-consuming and can
only be applied to small systems because the complete models,
\emph{i.e.} the models compound of all the observations, are
incrementally re-generated from scratch to improve the metrics.
An iterative process performed by adding the observations one
after another in the model could also be considered. Other
metrics could also be chosen depending on the context of the
software system. In \textit{Autofunk}, a similar improvement
would be to build submodels of a production system. By now, we
consider a whole workshop as a production system to infer models.
We distinguish the production lines, but apart from that, we do
not make any distinction among the different parts of the
workshop.  Nonetheless, there are parts that are more critical
than the others, at least in Michelin's workshops. Being able to
focus on specific locations of a workshop would be interesting to
build smaller models, and this should bring significant
improvements to the end users of \textit{Autofunk}.

\subsection{Scalability as a first-class citizen}

In this thesis, we tackled the problem of inferring models from
production systems. Such systems are distributed over several
devices, and generate thousands of events a day. Collecting,
storing, and analyzing such amount of data becomes more and more
complicated, and model inference algorithms have to take these
points into account. To our knowledge, too few studies
\cite{Yang:2006:PMT:1134285.1134325,Pradel:2009} take scalability
into account. That is also why we have proposed techniques that
scale well in this thesis. We shew that adopting contextual
algorithms was interesting for performance (\emph{e.g.}, our
context-specific reduction).  We also believe that the use of
specific parallel programming paradigms and heuristics would be
an interesting addition to quickly build models or to find state
equivalence classes. That is what we did in our Java
implementation. Besides, such challenges are close to those of
what we now call "big data" \cite{bigdata14}. This term not only
defines the large volume of data but also new processing
algorithms and applications since the traditional ones are
inadequate.

To pursue this path, applications in the Industry become more and
more complex with the rise of \emph{Service-Oriented
Architectures} (SOA), distributed systems, and more recently
\emph{microservices}\footnote{\url{http://martinfowler.com/articles/microservices.html}}
\cite{thones2015microservices}.  For instance, microservices are
emerging as a new architectural style, aiming at creating
software systems as a set of small services, \emph{i.e.} small
applications, each developed and deployed on its own. This
package of services form the complete software system. Inferring
models of such systems is not doable with most of the existing
model inference techniques. On the other hand, \textit{Autofunk}
can use many data sources to infer models. We chose to gather
heterogeneous events between different devices and software,
which could be a path to follow if one would want to infer models
of microservices as each service owns its data.

\subsection{Bringing together different methods and research
fields}

Some papers chose to combine different algorithms for optimizing
model inference. For instance, several works
\cite{Alur:2005:SIS:1047659.1040314,Raffelt:2005:LLA:1081180.1081189,ngll11}
replaced teachers and oracles with testers to answer queries.
Other works \cite{Azim13,WPX13} combined static analyses of
source code with crawlers to increase code coverage rates, and
reduce exploration time. Other  research domains, such as machine
learning and data mining, have also been considered to avoid the
classical state merging stage. Ammons \emph{et al.}
\cite{Ammons:2002:MS:565816.503275} developed a machine learning
approach, called specification mining to infer state machines.
The authors focused on the most frequent interaction patterns
found in a scenario set. In this thesis, we also adopted machine
learning to automatically slice a trace set into several subsets
so that we can infer several models of a production system in a
workshop (cf.
\crossref{sec:modelinf:prodsystems}{sec:modelinf:prodsystems:better-segmentation}).
Leveraging different domains such as the ones mentioned here
sounds promising for optimizing model inference. As an example,
state merging might be replaced with a kind of mechanism that
would be automatically extracted from the characteristics or the
context of the software system.

In the next section, we give some perspectives related to our
implementation of \emph{Autofunk}, the second main line of our
work (\emph{i.e.} software testing), and several ideas for future
works.
