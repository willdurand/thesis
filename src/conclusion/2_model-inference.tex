\section{New challenges for model inference}
\label{sec:conclusion:modelinf}

Model inference is a research field that has received a lot of
attention over the past three decades, and it is still gaining
ground with the emergence of new kinds of applications. Many
recent works consider model inference to later perform analyses
of the models or automatic testing in order to check different
aspects of the software system such as robustness, security, and
even regression testing, as presented in this thesis.
Nonetheless, model inference has a few drawbacks, which require
further investigation, and we believe that three major directions
could be very beneficial.

\subsection{Building exact, or rather, more precise models}
\label{sec:conclusion:modelinf:exact}

When the inferred models are used for analysis purpose, they must be as
precise as possible. Nonetheless, we observed that the main
feature leading to over-approximation is the state merging
process. A trivial solution would be to use minimization
techniques instead, \emph{e.g.}, a bisimulation minimization as
described in Chapter \ref{sec:modelinf:webapps} of this thesis.
As a reminder, the bisimulation relation associated with a
minimization technique merges the state sets that are bisimilar
equivalent. This relation is stronger than a classical trace
equivalence relation, but it may be considered too strong since the
bisimulation minimization usually does not merge enough states,
and thus may still produce large models. If another more suitable
relation can be used, and if verification or testing techniques
can work well with larger yet more precise models, which results
can we expect? In this thesis, we provided a preliminary answer
to this question, but there is still a lot of work that could be
done.

Many model inference techniques rely on the notion of abstraction
level to reduce the size of the inferred models. Nevertheless,
this process implies over-approximation. A solution to limit it
is to define and estimate \emph{quality metrics}
\cite{tonella2012finding,Lo20122063} to guide the model
construction. In \cite{tonella2012finding}, three metrics,
related to over- and under-approximation rates and model size,
are measured to balance over-approximation and
under-approximation of the inferred models with two search-based
algorithms: (i) a multi-objective genetic algorithm, and (ii) the
non-dominated sorting genetic algorithm \textit{NSGA-II}
\cite{deb2002fast}. But this process is time-consuming and can
only be applied to small systems because the complete models,
\emph{i.e.} the models compound of all the observations, are
incrementally re-generated from scratch to improve the metrics.
An iterative process performed by adding the observations one
after another in the model could also be considered. For
instance, with crawling techniques, every time a new state is
explored, these metrics could refine the state merging
on-the-fly. Other metrics could also be chosen depending on the
context of the software system. In \textit{Autofunk}, a similar
improvement would be to build submodels of a production system.
By now, we consider a whole workshop as a production system to
infer models, \emph{i.e.} we do not make any distinction among
the different parts of the workshop. Nonetheless, there are parts
that are more critical than the others, at least in Michelin's
workshops. Being able to focus on specific locations of a
workshop would be interesting to build smaller models. This
should bring significant improvements to the end users of
\textit{Autofunk}.

In addition, negative observations strongly help in the inference
of more precise models. Yet negative observations are usually not
taken into account in passive inference.  When the system is
available, a solution to collect negative observations would be
to exercise the system with \emph{Fuzz Testing}.  An execution
ended by a crash or the raise of an exception could then be
qualified as a negative observation.  Another solution, sometimes
considered with crawling techniques, would be to (re) incorporate
users in the model inference process to guide the generation of
observations. At the time of writing, it is often assumed that
the user either gives all the system paths to explore or does
nothing.

\subsection{Scalability as a first-class citizen}

Building models from large sets of observations in a reasonable
amount of time is a goal that is not yet met by most of the
existing model inference methods. To our knowledge, too few
studies \cite{Yang:2006:PMT:1134285.1134325,Pradel:2009} take
scalability into account. That is also why we have proposed
techniques that scale well in this thesis. We believe that the
use of specific parallel programming paradigms and heuristics
would be an interesting research direction, \emph{e.g.}, to
quickly build models or to find state equivalence classes. In
this thesis, we tackled the problem of inferring models from
production systems.  Such systems are distributed over several
devices, and generate thousands of events a day. Collecting,
storing, and analyzing such amount of data becomes more and more
complicated, and model inference algorithms have to take these
points into account. Such challenges are close to those of what
we now call "big data" \cite{bigdata14}. This term not only
defines the large volume of data but also new processing
algorithms and applications since the traditional ones are
inadequate.

To pursue this path, applications in the Industry become more and
more complex with the rise of \emph{Service-Oriented
Architectures} (SOA), distributed systems, and more recently
\emph{microservices}\footnote{\url{http://martinfowler.com/articles/microservices.html}}
\cite{thones2015microservices}.  For instance, microservices are
emerging as a new architectural style, aiming at creating
software systems as a set of small services, \emph{i.e.} small
applications, each developed and deployed on its own. This
package of services form the complete software system. Inferring
models of such systems is not doable with most of the existing
model inference techniques. On the other hand, \textit{Autofunk}
can use many data sources to infer models, because of our use
case with Michelin's production systems. Indeed, we chose such an
approach to gather heterogeneous events between different devices
and software, but this could be a path to follow if one would
want to infer models of microservices as each service owns its
data.

\subsection{Bringing together different methods and research
fields}

Some papers chose to combine different algorithms for optimizing
model inference. For instance, several works
\cite{Alur:2005:SIS:1047659.1040314,Raffelt:2005:LLA:1081180.1081189,ngll11}
replaced teachers and oracles with testers to answer queries.
Other works \cite{Azim13,WPX13} combined static analyses of
source code with crawlers to increase code coverage rates, and
reduce exploration time. Other  research domains, such as machine
learning and data mining, have also been considered to avoid the
classical state merging stage. Ammons \emph{et al.}
\cite{Ammons:2002:MS:565816.503275} developed a machine learning
approach, called specification mining to infer state machines.
The authors focused on the most frequent interaction patterns
found in a scenario set. In this thesis, we also adopted machine
learning to automatically slice a trace set into several subsets
so that we can infer several models of a production system in a
workshop (cf.
\crossref{sec:modelinf:prodsystems}{sec:modelinf:prodsystems:better-segmentation}).
Leveraging different domains such as the ones mentioned here
sounds promising for optimizing model inference. As an example,
state merging might be replaced with a kind of mechanism that
would be automatically extracted from the characteristics or the
context of the software system.

In the next section, we give some perspectives related to our
implementation of \emph{Autofunk}, the second main line of our
work (\emph{i.e.} software testing), and several ideas for future
works.
